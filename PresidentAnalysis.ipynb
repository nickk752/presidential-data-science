{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#r = requests.get('http://www.presidency.ucsb.edu/data.php')\n",
    "#soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(soup.prettify())\n",
    "def trainMarkov(url, name):\n",
    "    trumpmain = requests.get(url)\n",
    "    trumpsoup=BeautifulSoup(trumpmain.text, 'lxml')\n",
    "    root = 'http://www.presidency.ucsb.edu/'\n",
    "    table = trumpsoup.find('table', width=700)\n",
    "    links = []\n",
    "    path=str(\"./\"+ name +\".txt\")\n",
    "    for z in table.findAll('a'):\n",
    "        if('interview' not in z.text.lower()):\n",
    "            links.append(root+(z['href'])[3:])\n",
    "\n",
    "    trumpSpeeches = [requests.get(link , 'lxml')for link in links]\n",
    "    trumpSpeechesSoup=[BeautifulSoup(speech.text, 'lxml') for speech in trumpSpeeches]\n",
    "    \n",
    "\n",
    "    with open(path, \"a+\", encoding='utf-8') as outFile:\n",
    "        outFile.seek(0)\n",
    "        for i,speech in enumerate(trumpSpeechesSoup):            \n",
    "            outFile.write(trumpSpeechesSoup[i].find('span', class_='displaytext').text+'\\n')\n",
    "            \n",
    "    # Get raw text as string.\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Build the model.\n",
    "    text_model = markovify.Text(text)\n",
    "    return text_model\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(trumpSpeechesSoup[0].find('span', class_='displaytext').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for table in soup.findAll('td', class_='doclist'):\n",
    "    #print(table.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Donald-florida.txt'\n",
    "import markovify\n",
    "\n",
    "\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "#for i in range(5):\n",
    "#    print(text_model.make_sentence())\n",
    "\n",
    "# Print three randomly-generated sentences of no more than 140 characters\n",
    "#for i in range(3):\n",
    "#    print(text_model.make_short_sentence(140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hillarybot = trainMarkov('http://www.presidency.ucsb.edu/2016_election_speeches.php?candidate=70&campaign=2016CLINTON&doctype=5000', 'hillary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "berniebot = trainMarkov('http://www.presidency.ucsb.edu/2016_election_speeches.php?candidate=107&campaign=2016SANDERS&doctype=5000', 'bernie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nixonbot = trainMarkov('http://www.presidency.ucsb.edu/1960_election_speeches.php?candidate=37', 'nixon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trumpbot=trainMarkov('http://www.presidency.ucsb.edu/2016_election_speeches.php?candidate=45&campaign=2016TRUMP&doctype=5000', 'trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then she also wants to put an end to it on that same city block who just want to force the country under President Obama.\n",
      "We will also be able to get going, OK?\n",
      "Our country has ever done before.We will work.\n",
      "You have 39 days to change it.There's some breaking news about that on November 1st, they're trying to get tired of not taking them on jobs.\n",
      "We will terminate NAFTA and the Taliban in order to write this.\n",
      "She was hiding her criminal conduct by having her chief-of-staff declare herself to be a fair trader.\n",
      "That's why they've become vicious and vile.I will not lessen the danger, it will require military warfare, but also warm and fair-minded.\n",
      "235 days, no news conference on that same city block who just want a lot going on.Her great disloyalty to the American Dream.\n",
      "Then there was Russian money pouring into our poorest communities.Next, comes regulations.One of the other day?\n",
      "Just get me all of those places?\n",
      "So in theory it's supposed to be for sale, and important email records will no longer affordable.\n",
      "Bernie Sanders has, to use it, but I funded but I had that power.\n",
      "She lied to the Congress and the powerful a little more than 60% in Baltimore.\n",
      "And let me invite onto the world, and that is owned outright by the way, one of the world.\n",
      "We have $20 trillion in Iraq, $2 trillion.\n",
      "November 8, get out and vote, right?\n",
      "I'm going to get foreign companies to pool resources to fight for you.The job of the United Nations to really go with a solution.\n",
      "And more and more.\n",
      "I was going to Wharton or better than the rich people that have been left behind.Crime is through a failed political establishment.\n",
      "And I actually have a clue.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(trumpbot.make_short_sentence(max_chars=140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_combo = markovify.combine([ trumpbot, hillarybot ], [ 1, 1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've begun to change the fact that there are some issues that are making big investments in order to address this mounting mortgage crisis.\n",
      "And, of course, all across this state.\n",
      "As with so many who appreciate you and listening to folks here today from people who defend our values here at home.\n",
      "That gives me no pause.\n",
      "Now I know he took us out of love I'm talking about programs that hurt people.\n",
      "And if your interested to see the last 6 years, on behalf of your President again.A vote for change, but work to improve their homes.\n",
      "But Clinton is an honor.\n",
      "Just like you sir, you sir, you sir, you and I do believe in universal health care they need.Our annual trade deficit with the primary.\n",
      "No other country is founded on religious freedom.\n",
      "Back in 1995, she was nine years old.\n",
      "The soldiers from across the Middle East more unstable and dangerous globe.\n",
      "But you can't be done with the Republican rule.\n",
      "Since 9/11, hundreds of billions a year in America.\n",
      "And perhaps we can make the first place.\n",
      "The bill allowed the Chinese to buy health care compared to other countries.3.\n",
      "That's why I've set some goals.\n",
      "He didn't say is that, when they fly - they gave them to carry out specific duties in fighting terrorism?\n",
      "It's like trying to get the law and everyone is on C-SPAN when Elizabeth is absolutely opposite of love.\n",
      "One got in trouble too.\n",
      "I said, where did he come up with solutions and we made a contribution.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(model_combo.make_short_sentence(max_chars=140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import markovify\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "class POSifiedText(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        words = re.split(self.word_split_pattern, sentence)\n",
    "        words = [ \"::\".join(tag) for tag in nltk.pos_tag(words) ]\n",
    "        return words\n",
    "\n",
    "    def word_join(self, words):\n",
    "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e17e63955f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbettertrump\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPOSifiedText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrumpbot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\nick\\Anaconda3\\lib\\site-packages\\markovify\\text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_text, state_size, chain, parsed_sentences)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \"\"\"\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsed_sentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_sentences\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[1;31m# Rejoined text lets us assess the novelty of generated sentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\nick\\Anaconda3\\lib\\site-packages\\markovify\\text.py\u001b[0m in \u001b[0;36mgenerate_corpus\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfiltered\u001b[0m \u001b[0mthrough\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_sentence_input\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mpassing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_sentence_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mruns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\nick\\Anaconda3\\lib\\site-packages\\markovify\\text.py\u001b[0m in \u001b[0;36msentence_split\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mSplits\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtext\u001b[0m \u001b[0mstring\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \"\"\"\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msplit_into_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msentence_join\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\nick\\Anaconda3\\lib\\site-packages\\markovify\\splitters.py\u001b[0m in \u001b[0;36msplit_into_sentences\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[1;34mr\"(\\s+(?![a-z\\-–—]))\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Followed by whitespace + non-(lowercase or dash)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         ]), re.U)\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mdot_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpotential_end_pat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     end_indices = [ (x.start() + len(x.group(1)) + len(x.group(2)))\n\u001b[1;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdot_iter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\nick\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfinditer\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "bettertrump = POSifiedText(trumpbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
